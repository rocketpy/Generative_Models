# CLIP - CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs.

# https://github.com/openai/CLIP/tree/main


"""
Usage
First, install PyTorch 1.7.1 (or later) and torchvision, as well as small additional dependencies, and then install this repo as a Python package.
On a CUDA GPU machine, the following will do the trick:

$ conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0
$ pip install ftfy regex tqdm
$ pip install git+https://github.com/openai/CLIP.git
"""
